{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "482a9f0b-8907-4fd5-9735-027b571f2da6",
      "metadata": {
        "id": "482a9f0b-8907-4fd5-9735-027b571f2da6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f12065f-a937-4a2f-aff3-2a6a8e6fae8e",
      "metadata": {
        "id": "2f12065f-a937-4a2f-aff3-2a6a8e6fae8e"
      },
      "source": [
        "## *Data preprocessing*\n",
        "### We cant feed videos to CNN model directly. Since a video is just a series of frames the approach will be:\n",
        "#### 1) Loop over all frames in the video file\n",
        "#### 2) For each frame, pass the frame through the CNN\n",
        "#### 3) Obtain the predictions from the CNN\n",
        "#### 4) Maintain a list of the last K predictions\n",
        "#### 5) Compute the average of the last K predictions and choose the label with the largest corresponding probability\n",
        "#### 6) Label the frame and write the output frame to disk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37338aa9-c5b4-48fb-a1a0-aff8e0a38a64",
      "metadata": {
        "id": "37338aa9-c5b4-48fb-a1a0-aff8e0a38a64"
      },
      "source": [
        "## *Converting videos into frames and writing them in a seprate folder*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "27d5d622-232e-4c23-9896-c6d8d8a206b6",
      "metadata": {
        "id": "27d5d622-232e-4c23-9896-c6d8d8a206b6"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/drive/MyDrive/Human activity /sample_videos'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12fba58a-ce1a-4ca8-9c59-e9a0ec81ec80",
      "metadata": {
        "id": "12fba58a-ce1a-4ca8-9c59-e9a0ec81ec80"
      },
      "source": [
        "### Labeling different categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8e742d3b-f5c9-43b0-a9dd-2afd8f7c49c1",
      "metadata": {
        "id": "8e742d3b-f5c9-43b0-a9dd-2afd8f7c49c1"
      },
      "outputs": [],
      "source": [
        "categoeries = os.listdir(data_path)\n",
        "labels = [i for i in range(len(categoeries))]\n",
        "label_dict = dict(zip(categoeries, labels))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWJ5vR16iEIj",
        "outputId": "f8f49c1a-d4d7-4bd1-8fc2-5cd0e5b1b3b2"
      },
      "id": "TWJ5vR16iEIj",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "04398d0a-4a13-4ebc-afb7-ac8c8358240a",
      "metadata": {
        "id": "04398d0a-4a13-4ebc-afb7-ac8c8358240a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cd65e0-c99e-45d6-9aae-a1824ab38aa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Walkng_witthDog': 0, 'Handstand': 1, 'Fencing': 2, 'cricket': 3, 'Drumming': 4, 'typing': 5, 'writing_on_board': 6, 'tennis': 7, 'yo_yo': 8, 'Golf': 9, 'Bowling': 10, 'Boxing': 11, 'Brushing_Teeth': 12}\n",
            "['Walkng_witthDog', 'Handstand', 'Fencing', 'cricket', 'Drumming', 'typing', 'writing_on_board', 'tennis', 'yo_yo', 'Golf', 'Bowling', 'Boxing', 'Brushing_Teeth']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n"
          ]
        }
      ],
      "source": [
        "print(label_dict)\n",
        "print(categoeries)\n",
        "print(labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames = '/content/drive/MyDrive/Human activity /frames'\n",
        "if not os.path.exists(frames):\n",
        "    os.makedirs(frames)"
      ],
      "metadata": {
        "id": "CitwaXWamMSa"
      },
      "id": "CitwaXWamMSa",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "101209e2-b166-4d83-9b74-091b5ce2908f",
      "metadata": {
        "id": "101209e2-b166-4d83-9b74-091b5ce2908f"
      },
      "source": [
        "### For testing purpose we have short listed 10 activities the are:\n",
        "#### 'Bowling', 'Boxing', 'Brushing_Teeth', 'Fencing', 'Handstand', 'tennis', 'typing', 'Walkng_witthDog', 'writing_on_board', 'yo_yo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "8b64bf37-313b-4d4d-9672-17b863a7df68",
      "metadata": {
        "id": "8b64bf37-313b-4d4d-9672-17b863a7df68"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/drive/MyDrive/Human activity /frames' # Path for writing frames from videos"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=[] # Appending images as array in the list\n",
        "target=[] #Target list to make prediction"
      ],
      "metadata": {
        "id": "Q2YtK-Hdg4iE"
      },
      "id": "Q2YtK-Hdg4iE",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "675caf92-9f31-4f36-8c09-d9312b1e8c13",
      "metadata": {
        "id": "675caf92-9f31-4f36-8c09-d9312b1e8c13"
      },
      "source": [
        "### Reducing dimensions of pixels to (100x100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "825a4253-10c0-4415-b2de-5935eef83244",
      "metadata": {
        "id": "825a4253-10c0-4415-b2de-5935eef83244"
      },
      "outputs": [],
      "source": [
        "folder_count = 0\n",
        "img_size=100\n",
        "for items in categoeries: #looping over folders in categoeries\n",
        "    path = os.path.join(root_path, items) \n",
        "    folder_path = os.path.join(data_path,items)\n",
        "    img_names = os.listdir(folder_path) # Listing all files inside the directory\n",
        "    os.mkdir(path)\n",
        "    img_count= 0\n",
        "    folder_count +=1\n",
        "    \n",
        "    for img_name in img_names:\n",
        "            cap = cv2.VideoCapture(os.path.join(folder_path, img_name)) # Capcturing video and dividing it by frames\n",
        "            success, image = cap.read()\n",
        "            while success:\n",
        "                success, image = cap.read()\n",
        "                if not success:\n",
        "                    break\n",
        "                \n",
        "                \n",
        "                #gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Converting coloured image to greyScale\n",
        "                #norm = cv2.normalize(gray_image, None, alpha=0,beta=200, norm_type=cv2.NORM_MINMAX) # Normalize image\n",
        "                #resized_up = cv2.resize(image, down_points, interpolation= cv2.INTER_LINEAR) # Resizing image\n",
        "                resized=cv2.resize(image,(img_size,img_size))\n",
        "                cv2.imwrite(path + '/' + items +str(img_count) + '.jpg' , resized) # Writing image into to specified class with its class name \n",
        "                data.append(resized)\n",
        "                target.append(label_dict[items])\n",
        "                \n",
        "                img_count += 1\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea81b114-d664-4e14-985e-044657297653",
      "metadata": {
        "id": "ea81b114-d664-4e14-985e-044657297653"
      },
      "outputs": [],
      "source": [
        "#frames_path = '/content/drive/MyDrive/Human activity /frames'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b0d1c7d-e5de-4c05-9a26-9cbb5bdb8ade",
      "metadata": {
        "id": "7b0d1c7d-e5de-4c05-9a26-9cbb5bdb8ade"
      },
      "outputs": [],
      "source": [
        "#frames = os.listdir(frames_path)\n",
        "#label = [i for i in range(len(frames))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66b37a17-af06-4a5b-8a5b-b02d0fd26351",
      "metadata": {
        "id": "66b37a17-af06-4a5b-8a5b-b02d0fd26351"
      },
      "outputs": [],
      "source": [
        "#label_frames = dict(zip(frames,label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14bfb429-cee2-4dd2-9e4c-d3fefd93331d",
      "metadata": {
        "id": "14bfb429-cee2-4dd2-9e4c-d3fefd93331d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e51fcf83-c5c7-4411-e3b7-603d3da0ed9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'yo_yo': 0, 'typing': 1, 'Walkng_witthDog': 2, 'Fencing': 3, 'tennis': 4, 'writing_on_board': 5, 'Brushing_Teeth': 6, 'Handstand': 7, 'Boxing': 8, 'Bowling': 9}\n",
            "['yo_yo', 'typing', 'Walkng_witthDog', 'Fencing', 'tennis', 'writing_on_board', 'Brushing_Teeth', 'Handstand', 'Boxing', 'Bowling']\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
          ]
        }
      ],
      "source": [
        "#print(label_frames)\n",
        "#print(frames)\n",
        "#print(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70cb8d1-7559-4e16-b065-13575a9e24d6",
      "metadata": {
        "id": "a70cb8d1-7559-4e16-b065-13575a9e24d6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "935bb7a1-41d9-46df-ad31-92ed1d167c4d",
      "metadata": {
        "id": "935bb7a1-41d9-46df-ad31-92ed1d167c4d"
      },
      "outputs": [],
      "source": [
        "\n",
        "#for frame in frames:\n",
        " #   frame_path = os.path.join(frames_path, frame)\n",
        "  #  img_frames = os.listdir(frame_path)\n",
        "    \n",
        "   # for img_frame in img_frames:\n",
        "    #    imgPath = os.path.join(frame_path, img_frame)\n",
        "     #   frm = cv2.imread(imgPath)\n",
        "      #  data.append(frm)\n",
        "       # target.append(label_frames[frame])\n",
        "        \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742ce1ea-0635-4d74-b20a-91378d971445",
      "metadata": {
        "id": "742ce1ea-0635-4d74-b20a-91378d971445"
      },
      "source": [
        "### Recale and assign catagorical lables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "b75b6c4b-b190-411e-9e00-e3cf0c40edba",
      "metadata": {
        "id": "b75b6c4b-b190-411e-9e00-e3cf0c40edba"
      },
      "outputs": [],
      "source": [
        "data=np.array(data)/255.0\n",
        "data=np.reshape(data,(data.shape[0],img_size,img_size,3))\n",
        "target=np.array(target)\n",
        "from keras.utils import np_utils\n",
        "new_target=np_utils.to_categorical(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "23727e04-1edd-4524-9330-a71d240a9b71",
      "metadata": {
        "id": "23727e04-1edd-4524-9330-a71d240a9b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926c1d1c-5baf-403b-f05e-ff88fc2f9403"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10876, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e0c8c454-aff8-4e7a-91dc-9fb549ad368e",
      "metadata": {
        "id": "e0c8c454-aff8-4e7a-91dc-9fb549ad368e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b3a6619-c038-4585-e433-72795409a9df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10876, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "new_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c500eff-4d90-4227-a0bf-192a25613a1f",
      "metadata": {
        "id": "3c500eff-4d90-4227-a0bf-192a25613a1f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10364b0e-7952-444f-8e69-b0cdac17c095",
      "metadata": {
        "id": "10364b0e-7952-444f-8e69-b0cdac17c095"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "9614f73d-0892-469b-91bc-ed22d472c4b7",
      "metadata": {
        "id": "9614f73d-0892-469b-91bc-ed22d472c4b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1911079b-48a5-4987-c315-e1dfae7e4d8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10876, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "d71ff211-d823-44ec-b30a-8d2ed12196c2",
      "metadata": {
        "id": "d71ff211-d823-44ec-b30a-8d2ed12196c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b121f965-e6bf-4498-82c7-0ed56504f958"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data.shape[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0619272e-a8d3-4b06-8c2e-ef09726ab0c9",
      "metadata": {
        "id": "0619272e-a8d3-4b06-8c2e-ef09726ab0c9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "357b61c3-5002-4b1e-9787-00c91a2a7216",
      "metadata": {
        "id": "357b61c3-5002-4b1e-9787-00c91a2a7216"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "711cb0d3-d08f-4dfb-bd35-0995ff01b97a",
      "metadata": {
        "id": "711cb0d3-d08f-4dfb-bd35-0995ff01b97a"
      },
      "outputs": [],
      "source": [
        "model = Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d6de0419-47b2-4791-8d65-1dbafecde203",
      "metadata": {
        "id": "d6de0419-47b2-4791-8d65-1dbafecde203"
      },
      "outputs": [],
      "source": [
        "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(50,activation='relu'))\n",
        "\n",
        "model.add(Dense(13,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "c7b41472-bb7b-4575-aba4-e3d680b18f8f",
      "metadata": {
        "id": "c7b41472-bb7b-4575-aba4-e3d680b18f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74130dc7-8d08-4953-a672-226593c5a803"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 98, 98, 200)       5600      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 98, 98, 200)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 49, 49, 200)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 47, 47, 100)       180100    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 47, 47, 100)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 23, 23, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 52900)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 52900)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                2645050   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                663       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,831,413\n",
            "Trainable params: 2,831,413\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "83473b6a-0411-4cb0-889d-f3a7c35741ed",
      "metadata": {
        "id": "83473b6a-0411-4cb0-889d-f3a7c35741ed"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data,train_target,test_target=train_test_split(data,new_target,test_size=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "535326a9-5ebd-481b-b1eb-32dc0122f8d7",
      "metadata": {
        "id": "535326a9-5ebd-481b-b1eb-32dc0122f8d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c835b96-3c49-45e2-8e32-61d186840d2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 100, 100, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "train_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "3fc4b3d7-e9aa-467c-8c41-0d1c397998ce",
      "metadata": {
        "id": "3fc4b3d7-e9aa-467c-8c41-0d1c397998ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8073237-2fb0-4aa9-9f6c-e45e63e7fd69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "train_target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "5ab09c1a-8552-46bb-bb6c-7254a5230d3c",
      "metadata": {
        "id": "5ab09c1a-8552-46bb-bb6c-7254a5230d3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0957f54-8197-4732-8ca0-23b2b7795f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "167/167 [==============================] - 28s 107ms/step - loss: 0.3191 - accuracy: 0.9067 - val_loss: 3.3235e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 1.7912e-04 - accuracy: 1.0000 - val_loss: 8.6501e-05 - val_accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "167/167 [==============================] - 17s 102ms/step - loss: 5.9602e-05 - accuracy: 1.0000 - val_loss: 4.6268e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 3.2124e-05 - accuracy: 1.0000 - val_loss: 2.9678e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 2.4482e-05 - accuracy: 1.0000 - val_loss: 1.8197e-05 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 1.6430e-05 - accuracy: 1.0000 - val_loss: 1.3729e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 1.6156e-05 - accuracy: 1.0000 - val_loss: 1.2617e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 8.0652e-06 - accuracy: 1.0000 - val_loss: 7.5396e-06 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 6.5261e-06 - accuracy: 1.0000 - val_loss: 8.4787e-06 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 7.1864e-06 - accuracy: 1.0000 - val_loss: 6.5124e-06 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 4.4019e-06 - accuracy: 1.0000 - val_loss: 4.3446e-06 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 3.4000e-06 - accuracy: 1.0000 - val_loss: 3.5178e-06 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 3.5976e-06 - accuracy: 1.0000 - val_loss: 4.1078e-06 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 2.8531e-06 - accuracy: 1.0000 - val_loss: 2.5688e-06 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 1.9904e-06 - accuracy: 1.0000 - val_loss: 2.5300e-06 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 1.6319e-06 - accuracy: 1.0000 - val_loss: 1.6766e-06 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 1.5022e-06 - accuracy: 1.0000 - val_loss: 1.2590e-06 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 1.0644e-06 - accuracy: 1.0000 - val_loss: 1.0745e-06 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 1.0397e-06 - accuracy: 1.0000 - val_loss: 8.6093e-07 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 7.3882e-07 - accuracy: 1.0000 - val_loss: 9.4296e-07 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 7.4850e-07 - accuracy: 1.0000 - val_loss: 7.5895e-07 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "167/167 [==============================] - 17s 103ms/step - loss: 7.4102e-07 - accuracy: 1.0000 - val_loss: 8.6585e-07 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 4.6381e-07 - accuracy: 1.0000 - val_loss: 4.1643e-07 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 4.6074e-07 - accuracy: 1.0000 - val_loss: 3.7333e-07 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 3.7199e-07 - accuracy: 1.0000 - val_loss: 3.3282e-07 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "167/167 [==============================] - 17s 103ms/step - loss: 3.3919e-07 - accuracy: 1.0000 - val_loss: 3.5762e-07 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 3.2190e-07 - accuracy: 1.0000 - val_loss: 2.9024e-07 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "167/167 [==============================] - 17s 103ms/step - loss: 3.1557e-07 - accuracy: 1.0000 - val_loss: 2.1681e-07 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "167/167 [==============================] - 17s 102ms/step - loss: 2.5126e-07 - accuracy: 1.0000 - val_loss: 1.9389e-07 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 1.9169e-07 - accuracy: 1.0000 - val_loss: 1.8022e-07 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "167/167 [==============================] - 17s 101ms/step - loss: 2.0909e-07 - accuracy: 1.0000 - val_loss: 2.0914e-07 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 0.3863 - accuracy: 0.9446 - val_loss: 0.0042 - val_accuracy: 0.9982\n",
            "Epoch 33/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 8.4722e-05 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 6.9968e-05 - accuracy: 1.0000 - val_loss: 4.4421e-05 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 4.5251e-05 - accuracy: 1.0000 - val_loss: 2.8984e-05 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 3.1144e-05 - accuracy: 1.0000 - val_loss: 1.6961e-05 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 1.7910e-05 - accuracy: 1.0000 - val_loss: 1.0360e-05 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 9.5138e-06 - accuracy: 1.0000 - val_loss: 6.8809e-06 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 7.5950e-06 - accuracy: 1.0000 - val_loss: 5.3683e-06 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 4.7339e-06 - accuracy: 1.0000 - val_loss: 3.7120e-06 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.9302e-06 - accuracy: 1.0000 - val_loss: 2.7876e-06 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.6262e-06 - accuracy: 1.0000 - val_loss: 2.3940e-06 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.4668e-06 - accuracy: 1.0000 - val_loss: 2.4724e-06 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.6690e-06 - accuracy: 1.0000 - val_loss: 1.7454e-06 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.0475e-06 - accuracy: 1.0000 - val_loss: 1.2945e-06 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.3427e-06 - accuracy: 1.0000 - val_loss: 1.0538e-06 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.1611e-05 - accuracy: 1.0000 - val_loss: 3.3069e-06 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.1955e-06 - accuracy: 1.0000 - val_loss: 1.8347e-06 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.9839e-06 - accuracy: 1.0000 - val_loss: 1.5904e-06 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.6949e-06 - accuracy: 1.0000 - val_loss: 1.2125e-06 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.0342e-06 - accuracy: 1.0000 - val_loss: 9.0601e-07 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.4628e-06 - accuracy: 1.0000 - val_loss: 7.5049e-07 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.1579e-06 - accuracy: 1.0000 - val_loss: 6.2185e-07 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.0438e-06 - accuracy: 1.0000 - val_loss: 5.1711e-07 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 7.5347e-07 - accuracy: 1.0000 - val_loss: 4.3402e-07 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.1351e-07 - accuracy: 1.0000 - val_loss: 4.1184e-07 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.5537e-07 - accuracy: 1.0000 - val_loss: 3.6158e-07 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.0312e-07 - accuracy: 1.0000 - val_loss: 2.7594e-07 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 5.4268e-07 - accuracy: 1.0000 - val_loss: 3.2750e-07 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.5042e-07 - accuracy: 1.0000 - val_loss: 2.6289e-07 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.8714e-07 - accuracy: 1.0000 - val_loss: 2.2683e-07 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.9155e-07 - accuracy: 1.0000 - val_loss: 1.7704e-07 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.5752e-07 - accuracy: 1.0000 - val_loss: 1.9066e-07 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.2050e-07 - accuracy: 1.0000 - val_loss: 1.5501e-07 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.1988e-05 - accuracy: 1.0000 - val_loss: 6.2236e-06 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 0.0696 - accuracy: 0.9835 - val_loss: 6.7105e-04 - val_accuracy: 0.9996\n",
            "Epoch 67/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.6279e-05 - accuracy: 1.0000 - val_loss: 2.0083e-04 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 4.6827e-05 - accuracy: 1.0000 - val_loss: 2.5610e-05 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 6.8646e-05 - accuracy: 1.0000 - val_loss: 3.1735e-05 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 7.3114e-05 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.4402e-04 - accuracy: 1.0000 - val_loss: 2.3801e-05 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.9302e-05 - accuracy: 1.0000 - val_loss: 9.7796e-06 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.1051e-06 - accuracy: 1.0000 - val_loss: 9.7667e-06 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 3.3908e-06 - accuracy: 1.0000 - val_loss: 9.1425e-06 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.7001e-06 - accuracy: 1.0000 - val_loss: 9.7377e-06 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.6187e-06 - accuracy: 1.0000 - val_loss: 5.7491e-06 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4542e-06 - accuracy: 1.0000 - val_loss: 4.9196e-06 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 4.5130e-06 - accuracy: 1.0000 - val_loss: 2.1892e-06 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.9397e-06 - accuracy: 1.0000 - val_loss: 1.8906e-06 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4090e-04 - accuracy: 1.0000 - val_loss: 4.8886e-05 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 8.1667e-05 - accuracy: 1.0000 - val_loss: 4.7586e-06 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 3.0176e-06 - accuracy: 1.0000 - val_loss: 4.0994e-06 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.3711e-06 - accuracy: 1.0000 - val_loss: 3.6543e-06 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.6605e-06 - accuracy: 1.0000 - val_loss: 3.2512e-06 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.0986e-06 - accuracy: 1.0000 - val_loss: 3.0478e-06 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.1631e-06 - accuracy: 1.0000 - val_loss: 2.8818e-06 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 8.0168e-07 - accuracy: 1.0000 - val_loss: 2.7362e-06 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.4133e-06 - accuracy: 1.0000 - val_loss: 2.5467e-06 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 9.0459e-06 - accuracy: 1.0000 - val_loss: 2.9621e-06 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.0965e-06 - accuracy: 1.0000 - val_loss: 1.5782e-06 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 7.8661e-07 - accuracy: 1.0000 - val_loss: 1.0977e-06 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.6235e-06 - accuracy: 1.0000 - val_loss: 7.8318e-07 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.1307e-07 - accuracy: 1.0000 - val_loss: 6.8358e-07 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 5.7867e-07 - accuracy: 1.0000 - val_loss: 5.7108e-07 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.1313e-07 - accuracy: 1.0000 - val_loss: 4.8049e-07 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.5090e-07 - accuracy: 1.0000 - val_loss: 4.4887e-07 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 4.0652e-07 - accuracy: 1.0000 - val_loss: 3.9178e-07 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.0107e-07 - accuracy: 1.0000 - val_loss: 3.6934e-07 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4265e-07 - accuracy: 1.0000 - val_loss: 3.4294e-07 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.1355e-07 - accuracy: 1.0000 - val_loss: 3.2838e-07 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.7075e-07 - accuracy: 1.0000 - val_loss: 3.1168e-07 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 2.6005e-07 - accuracy: 1.0000 - val_loss: 2.8871e-07 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.4052e-07 - accuracy: 1.0000 - val_loss: 2.7843e-07 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 8.8920e-08 - accuracy: 1.0000 - val_loss: 2.6800e-07 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.3605e-07 - accuracy: 1.0000 - val_loss: 2.5448e-07 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.6135e-07 - accuracy: 1.0000 - val_loss: 2.3397e-07 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 6.6863e-08 - accuracy: 1.0000 - val_loss: 2.2927e-07 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.3531e-07 - accuracy: 1.0000 - val_loss: 2.0600e-07 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 1.1520e-07 - accuracy: 1.0000 - val_loss: 1.9086e-07 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.8830e-07 - accuracy: 1.0000 - val_loss: 1.5991e-07 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.4998e-06 - accuracy: 1.0000 - val_loss: 1.3664e-07 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 2.1760e-07 - accuracy: 1.0000 - val_loss: 1.0595e-07 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 7.0045e-07 - accuracy: 1.0000 - val_loss: 1.0501e-07 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.4854e-07 - accuracy: 1.0000 - val_loss: 1.8726e-07 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.7796e-07 - accuracy: 1.0000 - val_loss: 1.2375e-07 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.1460e-07 - accuracy: 1.0000 - val_loss: 9.5825e-08 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 4.8632e-08 - accuracy: 1.0000 - val_loss: 8.9144e-08 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.4246e-08 - accuracy: 1.0000 - val_loss: 7.9646e-08 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.2951e-08 - accuracy: 1.0000 - val_loss: 7.4844e-08 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 4.3263e-08 - accuracy: 1.0000 - val_loss: 6.8477e-08 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.7356e-08 - accuracy: 1.0000 - val_loss: 6.1900e-08 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 6.0172e-08 - accuracy: 1.0000 - val_loss: 6.2579e-08 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.3936e-08 - accuracy: 1.0000 - val_loss: 5.7725e-08 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.6643e-08 - accuracy: 1.0000 - val_loss: 5.5220e-08 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 9.2330e-08 - accuracy: 1.0000 - val_loss: 5.2245e-08 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.3443e-08 - accuracy: 1.0000 - val_loss: 4.7078e-08 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 3.2480e-08 - accuracy: 1.0000 - val_loss: 4.3320e-08 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 1.8209e-08 - accuracy: 1.0000 - val_loss: 3.9614e-08 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.7067e-08 - accuracy: 1.0000 - val_loss: 3.5595e-08 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.2013e-08 - accuracy: 1.0000 - val_loss: 3.2464e-08 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 9.9546e-09 - accuracy: 1.0000 - val_loss: 3.1316e-08 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.9573e-08 - accuracy: 1.0000 - val_loss: 2.8236e-08 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 1.4988e-08 - accuracy: 1.0000 - val_loss: 2.6775e-08 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.5994e-08 - accuracy: 1.0000 - val_loss: 2.3696e-08 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 6.8647e-08 - accuracy: 1.0000 - val_loss: 1.0704e-07 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.7963e-08 - accuracy: 1.0000 - val_loss: 4.4363e-08 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.5322e-08 - accuracy: 1.0000 - val_loss: 2.1503e-08 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 7.3149e-09 - accuracy: 1.0000 - val_loss: 1.9781e-08 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 7.7400e-09 - accuracy: 1.0000 - val_loss: 1.7380e-08 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.7984e-07 - accuracy: 1.0000 - val_loss: 5.1774e-08 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 4.3238e-08 - accuracy: 1.0000 - val_loss: 1.3883e-08 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "167/167 [==============================] - 16s 95ms/step - loss: 7.7847e-09 - accuracy: 1.0000 - val_loss: 9.4469e-09 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 7.9189e-09 - accuracy: 1.0000 - val_loss: 9.2382e-09 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.7806e-08 - accuracy: 1.0000 - val_loss: 5.5847e-09 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 6.3754e-09 - accuracy: 1.0000 - val_loss: 5.2193e-09 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.5256e-08 - accuracy: 1.0000 - val_loss: 5.4281e-09 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 5.1674e-09 - accuracy: 1.0000 - val_loss: 4.6452e-09 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.2660e-09 - accuracy: 1.0000 - val_loss: 4.2798e-09 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.9147e-09 - accuracy: 1.0000 - val_loss: 3.6013e-09 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 2.4607e-09 - accuracy: 1.0000 - val_loss: 3.3404e-09 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.1632e-09 - accuracy: 1.0000 - val_loss: 3.1838e-09 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 3.4897e-09 - accuracy: 1.0000 - val_loss: 3.2360e-09 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.0423e-09 - accuracy: 1.0000 - val_loss: 2.6097e-09 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.2370e-09 - accuracy: 1.0000 - val_loss: 2.4009e-09 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4831e-09 - accuracy: 1.0000 - val_loss: 2.3487e-09 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.3041e-09 - accuracy: 1.0000 - val_loss: 2.2443e-09 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 1.0514e-09 - accuracy: 1.0000 - val_loss: 2.2443e-09 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.6330e-09 - accuracy: 1.0000 - val_loss: 2.2965e-09 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.3041e-09 - accuracy: 1.0000 - val_loss: 1.9833e-09 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 1.4764e-09 - accuracy: 1.0000 - val_loss: 1.8790e-09 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 3.8273e-08 - accuracy: 1.0000 - val_loss: 9.7601e-09 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 6.3307e-09 - accuracy: 1.0000 - val_loss: 6.5241e-09 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 6.0846e-09 - accuracy: 1.0000 - val_loss: 4.0711e-09 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.5054e-09 - accuracy: 1.0000 - val_loss: 3.4447e-09 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.4897e-09 - accuracy: 1.0000 - val_loss: 3.3926e-09 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 2.6620e-09 - accuracy: 1.0000 - val_loss: 2.9228e-09 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.0066e-09 - accuracy: 1.0000 - val_loss: 2.7140e-09 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.9462e-09 - accuracy: 1.0000 - val_loss: 2.3487e-09 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "167/167 [==============================] - 16s 99ms/step - loss: 8.7913e-09 - accuracy: 1.0000 - val_loss: 2.1921e-09 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.0558e-08 - accuracy: 1.0000 - val_loss: 1.6702e-09 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 9.7532e-09 - accuracy: 1.0000 - val_loss: 7.8290e-10 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.3422e-10 - accuracy: 1.0000 - val_loss: 7.3070e-10 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.5659e-10 - accuracy: 1.0000 - val_loss: 7.3070e-10 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 1.2751e-09 - accuracy: 1.0000 - val_loss: 6.2632e-10 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.0266e-10 - accuracy: 1.0000 - val_loss: 6.7851e-10 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "167/167 [==============================] - 17s 100ms/step - loss: 2.9081e-10 - accuracy: 1.0000 - val_loss: 6.2632e-10 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.2370e-10 - accuracy: 1.0000 - val_loss: 6.7851e-10 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 6.7851e-10 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4607e-10 - accuracy: 1.0000 - val_loss: 6.7851e-10 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 3.8029e-10 - accuracy: 1.0000 - val_loss: 6.2632e-10 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4607e-10 - accuracy: 1.0000 - val_loss: 5.7413e-10 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 8.9480e-11 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "167/167 [==============================] - 16s 98ms/step - loss: 8.9480e-11 - accuracy: 1.0000 - val_loss: 5.7413e-10 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4831e-09 - accuracy: 1.0000 - val_loss: 6.0544e-09 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "167/167 [==============================] - 17s 99ms/step - loss: 9.1717e-10 - accuracy: 1.0000 - val_loss: 7.3070e-10 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.1409e-09 - accuracy: 1.0000 - val_loss: 5.7413e-10 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 5.3688e-10 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.4607e-10 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.3422e-10 - accuracy: 1.0000 - val_loss: 4.6974e-10 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 1.1185e-10 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 2.6844e-10 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.2370e-11 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 1.3422e-10 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 6.4873e-10 - accuracy: 1.0000 - val_loss: 6.7851e-10 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 6.7110e-10 - accuracy: 1.0000 - val_loss: 6.2632e-10 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 2.0133e-10 - accuracy: 1.0000 - val_loss: 6.2632e-10 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "167/167 [==============================] - 16s 97ms/step - loss: 4.4740e-11 - accuracy: 1.0000 - val_loss: 6.2632e-10 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 3.3555e-10 - accuracy: 1.0000 - val_loss: 5.2193e-10 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "167/167 [==============================] - 16s 96ms/step - loss: 4.4740e-11 - accuracy: 1.0000 - val_loss: 5.7413e-10 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_data,train_target,epochs=200,validation_split=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a9078203-3597-4ebe-af39-c4339e787e65",
      "metadata": {
        "id": "a9078203-3597-4ebe-af39-c4339e787e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "5ab310ab-b3a7-4ce2-eb64-daa3d03523b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "N = 200\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"center right\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a57060d1-2aef-4fb7-9152-769b3daa8fea",
      "metadata": {
        "id": "a57060d1-2aef-4fb7-9152-769b3daa8fea"
      },
      "outputs": [],
      "source": [
        "model.save(\"hra.h5\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "HRA.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}