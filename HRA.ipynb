{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "482a9f0b-8907-4fd5-9735-027b571f2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12065f-a937-4a2f-aff3-2a6a8e6fae8e",
   "metadata": {},
   "source": [
    "## *Data preprocessing*\n",
    "### We cant feed videos to CNN model directly. Since a video is just a series of frames the approach will be:\n",
    "#### 1) Loop over all frames in the video file\n",
    "#### 2) For each frame, pass the frame through the CNN\n",
    "#### 3) Obtain the predictions from the CNN\n",
    "#### 4) Maintain a list of the last K predictions\n",
    "#### 5) Compute the average of the last K predictions and choose the label with the largest corresponding probability\n",
    "#### 6) Label the frame and write the output frame to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37338aa9-c5b4-48fb-a1a0-aff8e0a38a64",
   "metadata": {},
   "source": [
    "## *Converting videos into frames and writing them in a seprate folder*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27d5d622-232e-4c23-9896-c6d8d8a206b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/ppras/ML/HRA/sample1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fba58a-ce1a-4ca8-9c59-e9a0ec81ec80",
   "metadata": {},
   "source": [
    "### Labeling different categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e742d3b-f5c9-43b0-a9dd-2afd8f7c49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoeries = os.listdir(data_path)\n",
    "labels = [i for i in range(len(categoeries))]\n",
    "label_dict = dict(zip(categoeries, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04398d0a-4a13-4ebc-afb7-ac8c8358240a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yo_yo': 0}\n",
      "['yo_yo']\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(label_dict)\n",
    "print(categoeries)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101209e2-b166-4d83-9b74-091b5ce2908f",
   "metadata": {},
   "source": [
    "### For testing purpose we have short listed 10 activities the are:\n",
    "#### 'Bowling', 'Boxing', 'Brushing_Teeth', 'Fencing', 'Handstand', 'tennis', 'typing', 'Walkng_witthDog', 'writing_on_board', 'yo_yo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8b64bf37-313b-4d4d-9672-17b863a7df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'C:/Users/ppras/ML/HRA/frames/' # Path for writing frames from videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675caf92-9f31-4f36-8c09-d9312b1e8c13",
   "metadata": {},
   "source": [
    "### Reducing dimensions of pixels to (100x100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5094e71-93cf-4e4c-80d6-d7a9ec7a030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "down_width = 100\n",
    "down_height = 100\n",
    "down_points = (down_width,down_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "825a4253-10c0-4415-b2de-5935eef83244",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_count= 0\n",
    "folder_count = 0\n",
    "for items in categoeries: #looping over folders in categoeries\n",
    "    path = os.path.join(root_path, items) \n",
    "    folder_path = os.path.join(data_path,items)\n",
    "    img_names = os.listdir(folder_path) # Listing all files inside the directory\n",
    "    os.mkdir(path)\n",
    "    folder_count +=1\n",
    "    \n",
    "    for img_name in img_names:\n",
    "            cap = cv2.VideoCapture(os.path.join(folder_path, img_name)) # Capcturing video and dividing it by frames\n",
    "            success, image = cap.read()\n",
    "            while success:\n",
    "                success, image = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "                \n",
    "                \n",
    "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # Converting coloured image to greyScale\n",
    "                norm = cv2.normalize(gray_image, None, alpha=0,beta=200, norm_type=cv2.NORM_MINMAX) # Normalize image\n",
    "                resized_up = cv2.resize(norm, down_points, interpolation= cv2.INTER_LINEAR) # Resizing image\n",
    "                cv2.imwrite(path + '/' + items +str(img_count) + '.jpg' , resized_up) # Writing image into to specified class with its class name \n",
    "                img_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaab740-9153-40de-b8f7-36415f77bb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
